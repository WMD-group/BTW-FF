{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL-34Jxn1npL"
      },
      "source": [
        "# Research Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBMK3w-U1npN"
      },
      "source": [
        "<div style=\"background-color: #f8d7da; border-left: 6px solid #ccc; margin: 20px; padding: 15px;\">\n",
        "    <strong>üí° Margaret Atwood:</strong> Every aspect of human technology has a dark side, including the bow and arrow.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgQDWVtq1npN"
      },
      "source": [
        "## üèÖ Build your own model\n",
        "\n",
        "We have just completed a session on generative AI (see [Lecture slides](https://speakerdeck.com/aronwalsh/machine-learning-for-materials-lecture-9)), but it is time to go back to supervised machine learning problems.\n",
        "\n",
        "You have been assigned one dataset from [MatBench](https://matbench.materialsproject.org) as introduced in the [Challenge slides](https://speakerdeck.com/aronwalsh/mlformaterials-challenge-25). You are free to choose and tune any machine-learning model, with any Python library, but it should be appropriate for the problem. For instance, [XGBoost](https://xgboost.readthedocs.io) could be a good starting starting point to build a regression model. You can refer back to earlier notebooks and repurpose code as needed.\n",
        "\n",
        "You may reach the limits of computing processing power on Google Colab. Building a useful model with limited resources is a real-world skill. Using other free resources is allowed if you find an alternative service, as is running on your own computer. A model tracker such as [wandb](https://wandb.ai) could be helpful for advanced users. If you want to try a brute force approach, a library such as [Automatminer](https://hackingmaterials.lbl.gov/automatminer) may be of interest.\n",
        "\n",
        "This notebook should be used for keeping a record of your model development, submission, and even your presentation. You are free to edit (add/remove/delete) or rearrange the cells as you see fit.\n",
        "\n",
        "### Your details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SNCKpT721npN",
        "outputId": "f03a69fd-5cad-43e4-f1d7-1912efa041cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the work of Junyi Wang [CID: 6009698]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Insert your values\n",
        "Name = \"Junyi Wang\" # Replace with your name\n",
        "CID = 6009698 # Replace with your College ID (as a numeric value with no leading 0s)\n",
        "\n",
        "# Set a random seed using the CID value\n",
        "CID = int(CID)\n",
        "np.random.seed(CID)\n",
        "\n",
        "# Print the message\n",
        "print(\"This is the work of \" + Name + \" [CID: \" + str(CID) + \"]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7qXCy0z1npO"
      },
      "source": [
        "## Problem statement\n",
        "\n",
        "You have been assigned one dataset from the [list](https://matbench.materialsproject.org/Benchmark%20Info/matbench_v0.1/) on [MatBench](https://matbench.materialsproject.org). You should state what problem you are trying to solve and comment on the best-performing model in the benchmark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PuUypDt-1npO"
      },
      "outputs": [],
      "source": [
        "# Spare cell\n",
        "\n",
        "# Problem Statement: Predicting Dielectric Constant with Machine Learning\n",
        "# 1. The objective of this study is to develop a best machine learning model to predict the dielectric constant of materials.\n",
        "#   The dielectric constant is a fundamental property that determines a material‚Äôs ability to store electrical energy, influencing its applications in electronics, semiconductors, capacitors,etc.\n",
        "#   Accurately predicting dielectric constants can accelerate the discovery of novel materials, reducing reliance on expensive and time-consuming Density Functional Theory (DFT) calculations.\n",
        "# 2. The dataset used in this study is sourced from MatBench, a benchmark suite for materials informatics, specifically the matbench_dielectric dataset.\n",
        "#   This dataset includes material compositions, structural descriptors, and experimentally measured dielectric constants.\n",
        "# 3. The problem is formulated as a regression task, where the goal is to predict a continuous target value based on material properties.\n",
        "\n",
        "# Best-Performing Model in the Benchmark\n",
        "# 1. According to the MatBench benchmark, the best-performing model for dielectric constant prediction is MODNet (v0.1.12), achieving:\n",
        "#   * Mean Absolute Error (MAE): 0.2711 and Mean RMSE: 1.6832 *, outperforming other models such as SchNet and DimeNet++ and Random Forest (RF-SCM/Magpie).\n",
        "# 2. MODNet is a deep learning-based model, has demonstrated superior performance compared to traditional machine learning models(RF, graph-based models)\n",
        "#   Its advantage lies in leveraging both structure-based and composition-based features, allowing it to capture complex, nonlinear relationships in materials data.\n",
        "\n",
        "# Research Plan\n",
        "# 1. In this Research Challenge, multiple regression machine learning models will be compared, including:\n",
        "#   * Traditional regression models: Linear Regression, Ridge Regression, Lasso\n",
        "#   * Tree-based models: Decision Trees, Random Forest\n",
        "#   * Neural Networks: Multi-Layer Perceptron (MLP)\n",
        "#   * Advanced Ensemble Models: Gradient BoostingÔºåXGBoost\n",
        "# 2, These models will be evaluated using cross-validation and metrics such as MAE, RMSE, and R¬≤ score to determine whether traditional\n",
        "#   and ensemble learning methods can achieve comparable performance to deeping learning model MODNet.\n",
        "#   Additionally, feature engineering (physics-informed descriptors) and hyperparameter optimization will be explored to further improve model accuracy.\n",
        "# 3. This study aims to compare different ML models for dielectric constant prediction and assess whether interpretable models\n",
        "#   like Random Forest and XGBoost can achieve competitive accuracy while offering better explainability than deep learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "NSAbcPYK1npO"
      },
      "source": [
        "## Data preparation\n",
        "\n",
        "Check the data distribution and apply appropriate pre-processing steps as required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7niWfR61npO"
      },
      "outputs": [],
      "source": [
        "# Installation of libraries\n",
        "!pip install matminer # Datasets and featurisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYrO_7Vq1npP"
      },
      "outputs": [],
      "source": [
        "# Get dataset info from matminer\n",
        "from matminer.datasets import get_all_dataset_info\n",
        "from matminer.datasets import load_dataset\n",
        "\n",
        "# Uncomment the info line for your assigned challenge\n",
        "\n",
        "  # A (GTAs - Xia, Kinga)\n",
        "#info = get_all_dataset_info(\"matbench_dielectric\")\n",
        "\n",
        "  # B (GTAs - Irea, Pan)\n",
        "#info = get_all_dataset_info(\"matbench_expt_gap\")\n",
        "\n",
        "  # C (GTAs - Yifan, Fintan)\n",
        "#info = get_all_dataset_info(\"matbench_glass\")\n",
        "\n",
        "# Check the dataset information\n",
        "print(info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Z7LzZIq1npP"
      },
      "outputs": [],
      "source": [
        "# Load your dataset into a pandas DataFrame\n",
        "df = load_dataset(\" \")\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9xrAWgC1npP"
      },
      "source": [
        "Choose relevant features, which may be based on composition or structure, depending on your problem. [matminer](https://hackingmaterials.lbl.gov/matminer/) is a good place to start."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuB4zHiS1npP"
      },
      "source": [
        "## Model selection, testing and training\n",
        "\n",
        "Define your model and justify your choice based on the problem and available data. You can look back at earlier notebooks and investigate other examples online including in [scikit-learn](https://scikit-learn.org)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ex8kDnn1npP"
      },
      "outputs": [],
      "source": [
        "# Spare cell\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jAX2y4z1npP"
      },
      "source": [
        "Train, validate and test your model. Make sure to do proper data splits and to consider the hyperparamaters of your model.\n",
        "\n",
        "<details>\n",
        "<summary>Note on the ROC-AUC classification metric</summary>\n",
        "There is one metric we didn't cover but is used in Matbench. In binary classification models, the ROC-AUC (Receiver Operating Characteristic - Area Under the Curve) score can be used to evaluate performance. It quantifies the ability of the model to distinguish between positive and negative instances across different decision thresholds. A higher ROC-AUC score (ranging from 0.5 to 1) indicates better performance, with 1 representing a perfect classifier and 0.5 indicating performance no better than random chance. There is a more detailed discussion here: https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc.\n",
        "\n",
        "The metric can be calculated using the `roc_auc_score` function from the `sklearn.metrics` module, e.g.\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Assuming you have true labels (y_true) and predicted probabilities (y_pred_prob)\n",
        "y_true = [...]  \n",
        "y_pred_prob = [...]  \n",
        "\n",
        "# Calculate ROC-AUC\n",
        "roc_auc = roc_auc_score(y_true, y_pred_prob)\n",
        "\n",
        "# Display the result\n",
        "print(f'ROC-AUC Score: {roc_auc:.4f}')\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0VV5r7Y1npP"
      },
      "outputs": [],
      "source": [
        "# Spare cell\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE04_uBx1npP"
      },
      "source": [
        "## Model analysis and discussion\n",
        "\n",
        "How well does your final model perform? Think of metrics and plots that are useful to dig a little deeper.\n",
        "\n",
        "Compare against the best-performing model on the [MatBench](https://matbench.materialsproject.org) leaderboard.  With limited resources, don't expect to match this performance, but you should do better than a baseline model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJQ5NzAR1npP"
      },
      "outputs": [],
      "source": [
        "# Spare cell\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKs9k4c21npP"
      },
      "source": [
        "## Large Language Model (LLM) usage declaration\n",
        "\n",
        "Acknowledge use of a generative model during your assignment. Points to consider:\n",
        "\n",
        "* State which LLM (e.g. GPT-4, Gemini, Co-Pilot)\n",
        "\n",
        "* Specify tasks (e.g. summarising research or code snippets)\n",
        "\n",
        "* Were any limitations/biases noted?\n",
        "\n",
        "* How did you ensure ethical use?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgsUih-e1npP"
      },
      "outputs": [],
      "source": [
        "# Spare cell\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLrLi5zy1npQ"
      },
      "source": [
        "## ‚òòÔ∏è Final word\n",
        "\n",
        "Good luck building your own model! We hope that you enjoyed the course and exercises. Dive deeper into the aspects that caught your interest. A useful starting point may be the [Resources](https://aronwalsh.github.io/MLforMaterials/Resources.html) page.\n",
        "\n",
        "Remember that submission is on Blackboard and you should upload both the completed Juypter Notebook (`.ipynb` file), as well as your recorded narrated presentation (maximum 5 minutes; see guides on using [Zoom](https://www.youtube.com/watch?v=H9qhoAIzW3E) or [Powerpoint](https://www.youtube.com/watch?v=Y5dgwwa5XRA) for this purpose)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}